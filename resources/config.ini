[data_creation]
data_name = standard_experiment
classes = 2
modals = flair, t2, t1ce, t1
bindings.height = 56, 184
bindings.width = 56, 184
bindings.pictures = 13, 141
raw_data_path = C:\Users\james\Uni_Projects\CS4_CompNeuroProj\src\data\raw
input_data_path = C:\Users\james\Uni_Projects\CS4_CompNeuroProj\src\data\processed
target_data_path = C:\Users\james\Uni_Projects\CS4_CompNeuroProj\src\data\processed
data_split.train = 0.8
data_split.validation = 0.1
data_split.testing = 0.1
data_augmentation.rotations = true
data_augmentation.mix_up = true
data_augmentation.flipping = true
special_operations.permutate_volumes = false
special_operations.super_permutate = false
special_operations.data_augmentation = false

[training]
experiment = fix_stuff
epoch = 51
batch = 128
output_size.height = 128
output_size.width = 128
save_path = C:\Users\james\Uni_Projects\CS4_CompNeuroProj\src\experiments\saved_model
learning_metrics = loss, accuracy, dice index, IoU
ilr.0 = 0.001
loss_function = Dice
optimizer = ADAM
alg_set_up.name = UNet
alg_set_up.parameters.building_block = conv2d, conv2d, relu
alg_set_up.parameters.stacks = 16, 32, 64
alg_set_up.parameters.kernel = 3
alg_set_up.parameters.stride = 1
alg_set_up.parameters.max_pool = 2
special_operations.continually_save_model = false
special_operations.create_data = false

[testing]
metrics = hausdorff, dice_loss

[graphing]
experiment_location = C:\Users\james\Uni_Projects\CS4_CompNeuroProj\src\experiments\saved_model\fix_stuff
model_name = model.pth
loss_loc = Graph\train_loss.pkl
data_input_loc = C:\Users\james\Uni_Projects\CS4_CompNeuroProj\src\data\processed\standard_experiment
exp_loc = inputs\epoch_121.pt
label_loc = targets\epoch_121.pt
segmentation_res = true
model_loss = true
hd = true
iou = true
accuracy = true